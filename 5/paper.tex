\RequirePackage[l2tabu,orthodox]{nag} % turn on warnings because of bad style
\documentclass[a4paper,11pt,bibtotoc]{scrartcl}

\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{0394}{\Delta}
\usepackage[T1]{fontenc}        % Tries to use Postscript Type 1 Fonts for better rendering
\usepackage{lmodern}            % Provides the Latin Modern Font which offers more glyphs than the default Computer Modern
\usepackage[intlimits]{amsmath} % Provides all mathematical commands

\usepackage{hyperref}           % Provides clickable links in the PDF-document for \ref
\usepackage{grffile}            % Allow you to include images (like graphicx). Usage: \includegraphics{path/to/file}

% Allows to set units
\usepackage[ugly]{units}

% Additional packages
\usepackage{url}                % Lets you typeset urls. Usage: \url{http://...}
\usepackage{breakurl}           % Enables linebreaks for urls
\usepackage{xspace}             % Use \xpsace in macros to automatically insert space based on context. Usage: \newcommand{\es}{ESPResSo\xspace}
\usepackage{xcolor}             % Obviously colors. Usage: \color{red} Red text
\usepackage{booktabs}           % Nice rules for tables. Usage \begin{tabular}\toprule ... \midrule ... \bottomrule

% Source code listings
\usepackage{listings}           % Source Code Listings. Usage: \begin{lstlisting}...\end{lstlisting}
\lstloadlanguages{python}       % Default highlighting set to "python"

\usepackage{epsfig}
\usepackage{cleveref}
\usepackage{subcaption}

\title{Worksheet 5: Thermostats, Monte Carlo}
\author{Evangelos Ribeiro Tzaras \and Marvin Poul}

\begin{document}

\maketitle

\section{Thermostats}

\subsection{Anderson Thermostat}

The Anderson algorithm describes random collisions of the simulated particles
with a heat bath with a frequency $\nu$, as such the higher $\nu$ the more
directly are the system dynamics influence the these thermic collisions rather
than system properties, e.g.\ concentration gradients in the case of the
diffusivity.

\subsection{Nos\' e-Hoover Thermostat}

Choosing $L = 3N + 1$ leads to the ensemble average in the Nos\' e-ensemble
being directly equal the ensemble average in the NVT-ensemble, whereas $L = 3N$
leads to constant time steps.

\subsection{Berendsen Thermostat}

The equipartition theorem gives
\begin{equation*}
    \bar v^2 = 3\frac{k_BT}{m}
\end{equation*}
for the mean velocity at a given temperature. Rescaling all velocities by
$\lambda$ then yields for the kinetic energy
\begin{align*}
    E_\mathrm{kin}' &= \frac{1}{2}m\bar v'^2 = \frac{1}{2}mv^2\lambda^2 \\
    &= \frac{3k_B }{2}\left(T + \frac{\Delta t}{\tau_T}(T' - T)\right) \\
\end{align*}
or, as the difference between before and after the rescaling,
\begin{align*}
    Î”E_\mathrm{kin} &= \frac{3k_B }{2m}\left(T + \frac{\Delta t}{\tau_T}(T' -
    T)\right) - \frac{3}{2}k_BT \\
    &= \frac{3k_B}{2\tau_T}\Delta t\Delta T,
\end{align*}
where $\Delta T = T' - T$. Formulating this as an energy flux $J =
\frac{E}{\Delta t}$ gives the desired expression
\begin{equation*}
    J = \frac{3k_B}{2\tau_T}\Delta T = \alpha \Delta T
\end{equation*}
from which
\begin{equation*}
    \alpha = \frac{3k_B}{2\tau_T}
\end{equation*}
follows directly by comparison.

\section{Simple Sampling --- Integration}

The Runge-function has been plotted in \cref{fig:runge} and the statistical and
actual error in \cref{fig:error}. The code used is in the file \texttt{ex3.py}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{runge}
    \caption{The Runge-function in the intervall $[-5,5]$}
    \label{fig:runge}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{error}
    \caption{Errors for different sample sizes, (example run)}
    \label{fig:error}
\end{figure}

\section{Importance Sampling --- Metropolis-Hastings Algorithm}

In the Metropolis-Hastings-Algorithm a number $N$ of samples are generated
for a given distribution function $P$ starting from an initial state $\phi_0$.
From a state $\phi_i$ a new state $\phi\prime$ is obtained through a so-called trial move.
If $P\left(\phi\prime\right) > P\left(\phi_i\right)$ then the state
$\phi\prime$ is always accepted. Otherwise $\phi\prime$ will be accepted
with a probabilty of
$\frac{P\left(\phi\prime\right)}{P\left(\phi_i\right)}$.
When the state is accepted, the next state is $\phi_{i+1}=\phi\prime$ and
when it's rejected$\phi_{i+1}=\phi_i$.

In the excercise generated $N$ samples of $x$ that are distributed
according to the Runge function. The trial move displaces $x$ by a
uniformly distributed random number $r \in \left[-\Delta x,\Delta x\right]$.
$N=100000$ samples each were generated for trial move ranges
$\Delta x \in \left\{0.1, 1.0, 10.0, 100.0\right\}$.

Compairing \cref{fig:hist_runge} and \cref{fig:runge} we can see that both
the $\Delta x = 1.0$ and $\Delta x = 10.0$ cases yield reasonable results.
Taking the acceptance ratios for the different trial move ranges into account
\cref{tab:acceptance} we argue that the $\Delta x = 1.0$ case with an acceptance
ratio of $\sim 85\%$ is the best choice for $\Delta x$ because it looks the smoothest.
Judging by the acceptrance ratio, we would choose $\Delta x = 10.0$.
This is because a too high acceptance ratio leads to highly correlated data,
while a too low ratio will almost never change states and would require
a larger number of samples in order to obtain reasonable results.
This can be seen if we look at the $\Delta x = 100.0$ case in our figures:
The histogram shows high bars surrounded by lower bars although we would expect
to find a relatively smooth looking 'curve'.
We could in theory take less bins for the histograms, but this could be unsatisfactory
when details are to be observed. The trial moves simply 'jump too far'
and lead to oversampling of certain regions of $x$.
For $\Delta x = 0.1$ the 'jumps' are very narrow and we can see that the algorithm
has difficulties giving a correct symmetric result because the region where a transition
from a state $x<0$ to a state $x>0$ is possible is just $\left]-\Delta x, \Delta x \right[$.
So once we are on either side of the peak we will likely stay there.

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{hist_runge}
  \caption{Histogram of obtained samples for different trial move ranges}
  \label{fig:hist_runge}
\end{figure}

\begin{table}
  \centering
  \begin{tabular}{c | c}
    $\Delta x$ & acceptance ratio \\
    0.1 & 98.3\% \\
    1.0 & 85.3\% \\
    10.0 & 33.4\% \\
    100.0 & 6.1\%
  \end{tabular}
 \caption{Acceptance ratio for different trial move ranges}
 \label{tab:acceptance}
\end{table}


\section{2D Ising Model --- Exact Summation vs Metropolis Monte Carlo}

In this excercise we simulated the 2 dimensional Ising model on a square lattice
(LxL) with periodic boundary conditions. $\sigma_{i,j}$ corresponds to the spin
at lattice position $(i,j)$. As no external field is present the (total) energy
of the system is given by

\begin{align}
  E &= \frac{1}{2} \sum_{i=0}^{L-1} \sum_{j=0}^{L-1} E_{i,j} \\
  E_{i,j} &= -\sigma_{i,j} \left(\sigma_{i-1,j} + \sigma_{i+1,j} + \sigma_{i,j-1} + \sigma_{i,j+1} \right)
\end{align}

We were interested in two observables, namely the (mean) \textit{energy per site} $e$
and the (mean) \textit{magnetization per site} $m$, which are defined as follows

\begin{align}
  e &= \left\langle \frac{E}{L^2} \right\rangle \\
  m &= \left\langle \left| \mu \right| \right \rangle \\
  \mu &= \frac{1}{L^2} \sum_{i=0}^{L-1} \sum_{j=0}^{L-1} \sigma_{i,j}
\end{align}

The two methods we used for the study of our system are
\begin{itemize}
  \item Exact summation over all $2^{4*4}=65536$ states
  \item Metropolis Monte Carlo as described in the previous section
\end{itemize}

While the exact summation obviously gives exact results the computational cost grows
exponentially with the number of spins in the system.
Exact summation for larger systems is not computationally feasible.
The Monte Carlo simulation was performed to yield 10000 samples.
The results can be seen in \cref{fig:energy_per_site} and \cref{fig:magnetization_per_site}.
We can see that the MC results are somewhat 'jiggery' which is due to the fact that we only generate
a relatively small number of samples.
Overall we have good agreement from both results and although this may not be the case for our
(4x4) system, for larger systems the MC simulation will always outperform exact summation.
    
\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{energy_per_site}
  \caption{Mean energy per site}
  \label{fig:energy_per_site}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{magnetization_per_site}
  \caption{Mean magnetization per site}
  \label{fig:magnetization_per_site}
\end{figure}


\end{document}
